# nvidia_dli
인간으로서 우리는 우리의 경험을 바탕으로 우리가 보는 것을 일반화합니다. 비슷한 방법으로 우리는 머신 러닝이라고 불리는 인공지능의 한 분야를 사용하여 경험을 바탕으로 많은 예제 데이터들을 일반화하고 분류할 수 있습니다. 특히, 딥 뉴럴 네트워크 모델 또는 딥 러닝을 사용하여 이미지 데이터세트에서 관련 패턴을 인식하고 궁극적으로 새로운 이미지를 일치시켜 정답을 얻을 수 있습니다. 딥 러닝 모델은 입력을 출력에 매핑하도록 구성된 내부 파라미터(Parameter) 또는 가중치(Weight)를 가진 뉴럴 네트워크로 구성됩니다. 이미지 분류에서 입력은 카메라 이미지의 픽셀이며 출력은 모델이 인식하도록 훈련된 가능한 범주(Category) 또는 클래스(Class)입니다. 클래스는 1000개의 다른 객체일 수도 있고 또는 2개의 객체 만일 수도 있습니다. 여러 개의 레이블이 지정된 예제를 모델에 제공하여 이미지를 인식할 수 있도록 훈련(Train)해야 합니다. 모델은 훈련한 후에는 실시간 데이터에서 실행하여 실시간으로 결과를 제공할 수 있어야 하며 이 과정을 추론(Inference)이라고 합니다.
훈련 전에는 가중치가 잘못되어 있으므로 모델이 이미지 입력에 대해 정확한 클래스를 지정하기가 어렵습니다. 레이블이 지정된 이미지 예시는 반복적으로 학습 알고리즘(Learning Algorithm)을 사용하여 네트워크에 제출됩니다. 네트워크에서 "잘못된" 답을 할당하면 (라벨이 일치하지 않는 경우) 학습 알고리즘은 가중치를 약간 조정합니다. 계산 집약적인 반복 작업을 여러번 거칠 수록 정확도는 향상되어 모델이 입력 이미지에 대한 클래스를 안정적으로 결정할 수 있습니다.
입력되는 데이터는 좋은 모델을 만드는 핵심 중에 하나 입니다. 즉, 표시된 이미지의 배경, 각도, 또는 다른 "노이지한" 측면에도 관계 없이 잘 일반화를 할 수 있게 합니다. 데이터 세트 또는 에포크(Epoch)를 추가로 통과할수록 모델 성능을 향상시킬 수 있기도 합니다.
딥 러닝은 Convolutional Neural Network (CNN) 모델에 의존하여 이미지를 예측된 분류로 변형합니다. CNN이란 Artificial neural network(인공 신경망)의 한 클래스이며 합성곱 레이어(컨볼루션 레이어)를 활용하여 유용한 정보를 위해 인풋을 필터링하며 이미지 애플리케이션에서 선호되는 네트워크 입니다.
인공 신경망은 생물학적으로 영감을 받은 계산 모델로서, 인간의 뇌에 존재하는 뉴런의 네트워크를 본떠 만들어졌습니다. 각 계층에서 네트워크는 가중치 입력 합에 비선형 함수를 적용하여 입력 데이터를 변형합니다. 하나의 레이어(계층)에서 중간 출력 값은 다음 레이어의 입력으로 사용됩니다. 반복된 변형을 통한 뉴럴 네트워크는 비선형 형상 (엣지와 모양) 의 여러 레이어들을 학습하고 마지막 레이어에어 결합하여 (더 복잡한) 객체의 예측 값을 생성합니다.
CNN 전용 컨볼루션 연산은 한 레이어의 입력 데이터(피쳐 맵)와 컨볼루션 커널 (필터)를 결합하여 다음 계층을 위한 변환된 피쳐 맵을 구성합니다. 이미지 분류를 위한 CNN은 일반적으로 입력 계층(이미지), 형상 추출을 위한 일련의 숨겨진 레이어들 (컨볼루션), 그리고 완전히 연결된 출력 레이어(fully connected output layer, 분류)로 구성됩니다.
cnn그림 1: 교통 신호의 입력 이미지는 4개의 피쳐 맵을 생성하는 4개의 5X5 컨볼루션 커널로 필터링됩니다. 이러한 피쳐 뱁은 맥스 풀링을 통해 하위 샘플링됩니다. 다음 레이어는 이 하위 샘플링된 이미지에 10개의 5X5 컨볼루션 커널을 적용하고 다시 피쳐 맵을 풀링합니다. 마지막 레이어에서는 모든 생성된 피쳐가 결합되어 분류기에 사용될 수 있는 완전히 연결된 레이어로 구성됩니다. (기본적으로 logistic regression). Image by Maurice Peemen.
CNN은 훈련을 받으면 분류의 요구 사항에 따라 가장 관련성이 높은 기능을 찾기 위해 자동으로 조정됩니다. 예를 들어, CNN은 일반적인 물체 인식 작업에 직면했을 때는 물체의 모양에 대한 정보를 필터링하지만 새에 대한 인식 작업에 직면했을 때는 새의 색을 추출합니다. 이것은 서로 다른 객체 클래스는 다른 모양을 가지고 있지만 새의 여러 종류는 여러 모양보다는 색깔에서 더 다를 가능성이 있다는 점에 대해 훈련을 통한 CNN의 인식이 바탕이 됩니다.
CNN 모델을 훈련하고 훈련된 모델을 통해 추론을 실행하는 데 필요한 광범위한 연산 작업이 상당히 많을 수 있으므로 인텐시브한 연산 자원과 시간이 필요합니다. Caffe, TensorFlow,PyTorch와 같은 딥 러닝 프레임워크는 GPU에서 더 빠르게 실행되도록 최적화되어 있습니다. 프레임워크는 GPU가 있는 경우 GPU의 병렬 처리 기능을 활용하여 훈련 및 추론 작업을 가속화 합니다.
젯슨 나노는 128 코어의 NVIDIA Maxwell GPU를 포함하고 있습니다. 풀 트레이닝 프레임워크를 실행할 수 있기 때문에, 전이학습(Transfer Learning)을 통해 네트워크를 재학습할 수도 있습니다.
이미지 분류 및 회귀를 위해서 개발자들이 활용할 수 있는 세계적인 수준의 CNN 아키텍처는 많이 있습니다. PyTorch와 다른 프레임워크에서는 유명한Imagenet Large Scale Visual Recognition Challenge (ILSVRC)의 과거 우승 솔루션의 사전 훈련 모델들에 액세스할 수 있는 기능이 포함되어 있습니다. 이 챌린지에서 연구원들은 정확하게 객체와 장면을 분류하고 감지할 수 있도록 서로 경쟁합니다. 2015년도에는 ResNet이 이미지 분류, 감지, 지역화 부분에서 상을 휩쓸었습니다. 이번 프로젝트에서는 ResNet 중 가장 작은 버전인 ResNet-18을 사용할 예정입니다.
Deep Residual Learning for Image Recognition 연구 논문은 왜 이 아키텍쳐가 효과적인지에 대한 인사이트를 제공하고 있습니다. ResNet은 하나 이상의 레이어를 건너 뛰는 "shortcut connections"를 통합하는 빌딩블록으로 만들어진 residual network입니다.
이 shortcut 결과는 건너 뛴 레이어들의 결과들에 추가 됩니다. 저자는 이 기술은 네트워크를 최적화하기에 용이하게 만들어 주고 크게 향상된 뎁스에도 더 높은 정확도 향상을 얻을 수 있음을 입증하였습니다. ResNet 아키텍처는 18개의 레이어 깊이에서 152개의 레이어 깊이까지 다양한 범위를 가지고 있습니다. 우리는 여기서 가장 작은 네트워크인 ResNet-18을 사용하고 이 것은 젯슨 나노에 적합한 성능과 효율적인 크기와의 균형을 제공합니다.
전이학습:PyTorch는 ImageNet 2012 classification dataset에서 훈련된 사전 훈련된 ResNet-18 모델을 포함하고 있습니다. 다시 말해서 모델은 이미 1000개의 다른 개체들을 인식할 수 있습니다.
훈련된 뉴럴 네트워크 내에는 윤곽선, 곡선, 선 및 이미지의 식별 가능한 특징을 찾는 레이어들이 있습니다. 기존 모델 훈련 시 학습된 중요한 이미지 특징들들은 우리의 분류 작업을 위해 재사용 가능합니다.
우리는 ResNet-18 모델을 구성하는 18개의 마지막 네트워크 레이어를 수정하여 모두 10개 미만의 클래스를 포함하도록 이번 프로젝트에 맞게 조정할 것 입니다. ResNet-18 모델의 마지막 레이어는 완전히 연결된 (fully connected, fc) 레이어로 512개의 입력으로 풀링(pooled)되고 평탄화(flatten)되어 1000개의 가능한 출력 클래스로 연결됩니다. 우리는(512,1000)레이어를 클래스에 맞는 레이어로 교체 합니다. 예를 들어 3개의 클래스만 필요한 경우, 최종 레이어는 (512, 3)가 되어 각 512개의 입력이 3개의 출력 클래스 각각에 완전히 연결됩니다.
수집한 이미지를 사용하여 이러한 3가지 클래스를 인식할 수 있도록 네트워크를 훈련해야 하지만 네트워크는 이미 대부분의 개체에 공통적인 기능을 인식하도록 학습되어 있기 때문에 훈련 과정은 이미 부분적으로는 수행된 것이라고 할 수 있습니다. 이전 훈련은 재사용 가능하며 새로운 프로젝트로 "transferred(이전)"할 수 있습니다.
